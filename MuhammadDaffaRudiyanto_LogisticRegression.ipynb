{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvoLLiZNL36d"
      },
      "outputs": [],
      "source": [
        "#import all necessary libraries\n",
        "%reset -f\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kfClxq6L7Kh"
      },
      "outputs": [],
      "source": [
        "# Read and store the CSV file into a variable\n",
        "data = pd.read_csv('dataset_elec_4000.csv')\n",
        "data = data[['review','rating']]\n",
        "\n",
        "#Set a variable for positive reviews counter\n",
        "positive = 0 \n",
        "\n",
        "# Set a variable for negative reviews counter\n",
        "negative = 0 \n",
        "\n",
        "for i in range(len(data['rating'])):\n",
        "  # Counts the amount of positive reviews in the data set\n",
        "  if data['rating'][i] == 1.0:\n",
        "    positive += 1 \n",
        "  # Counts the amount of negative reviews in the data set\n",
        "  else:\n",
        "    negative += 1 \n",
        "\n",
        "# Rrint the amount of positive reviews\n",
        "print(\"Positive review:\", positive) \n",
        "\n",
        "# print the amount of negative reviews\n",
        "print(\"Negative review:\", negative) \n",
        "\n",
        "# Print the data variable for checking purposes, whether or not the contents of the CSV file has been read and stored properly\n",
        "print(data) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split the dataset into four, namely X_train and Y_train for training purposes, while X_test and Y_test for testing purposes\n",
        "X_train, X_test, Y_train, Y_test  = train_test_split(\n",
        "        data['review'], \n",
        "        data['rating'],\n",
        "        test_size=0.25, \n",
        "        random_state=np.random)"
      ],
      "metadata": {
        "id": "HI_D-gcyQOK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the size of the training dataset for checking purposes\n",
        "print(X_train.shape,Y_train.shape)\n",
        "\n",
        "# Print the size of the testing dataset for checking purposes\n",
        "print(X_test.shape,Y_test.shape)"
      ],
      "metadata": {
        "id": "wgzOewPXZkol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#enable scikit-learn's function to vectorize and clean words  and assign it to variable\n",
        "vectorizer = TfidfVectorizer(lowercase=True)\n",
        "\n",
        "#vectorize the X_train data (the review texts used for training purposes) with the fit trasnform function\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "\n",
        "#vectorize the X_test data (the unseen review text used for testing purposes) \n",
        "X_test_vec = vectorizer.transform(X_test)\n"
      ],
      "metadata": {
        "id": "WxwgNguKDQEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the size of the training dataset after vectorization for checking purposes\n",
        "print(X_train_vec.shape,Y_train.shape)\n",
        "\n",
        "# Print the size of the testing dataset after vectorization for checking purposes\n",
        "print(X_test_vec.shape,Y_test.shape)"
      ],
      "metadata": {
        "id": "zLCeqd_5kcm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enabling the Logistic Regression function and assign it to a variable\n",
        "lr = LogisticRegression()\n",
        "\n",
        "# Train the model with the  training dataset (X_train_vec and Y_train)\n",
        "lr.fit(X_train_vec, Y_train)\n",
        "\n",
        "#assign the result of the trained model into a variable\n",
        "results = lr.predict(X_test_vec)"
      ],
      "metadata": {
        "id": "mwoCYoNxQ450"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate the accuracy score of the model\n",
        "acc_rf = accuracy_score(Y_test, results)\n",
        "\n",
        "#Calculate the F1 score of the model\n",
        "f1_rf = f1_score(Y_test, results)\n",
        "\n",
        "#Calculate the precision score of the model\n",
        "precision_rf = precision_score(Y_test, results)\n",
        "\n",
        "#Calculate the recall score of the model\n",
        "recall_rf = recall_score(Y_test, results)\n",
        "\n",
        "print(\"Evaluation of Logistic Regression for Sentiment Analysis:\")\n",
        "\n",
        "#Print the accuracy score of this model\n",
        "print(\"Accuracy   : \", acc_rf)\n",
        "\n",
        "#Print the precision score of this model\n",
        "print(\"Precision  : \", precision_rf)\n",
        "\n",
        "#Print the recall score of this model\n",
        "print(\"Recall     : \", recall_rf)\n",
        "\n",
        "#Print the F1 score of this model\n",
        "print(\"F1 Score   : \", f1_rf)"
      ],
      "metadata": {
        "id": "irT3Ck36sOQ-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}